import cv2
import argparse

from ultralytics import YOLO
import supervision as sv
import numpy as np
import pyttsx3


engine = pyttsx3.init("sapi5")
voices = engine.getProperty("voices")
engine.setProperty("voice", voices[0].id)
rate = engine.setProperty("rate", 170)


def speak(audio):
    engine.say(audio)
    engine.runAndWait()

ZONE_POLYGON = np.array([
    [0, 0],
    [0.5, 0],
    [0.5, 1],
    [0, 1]
])


def parse_arguments() -> argparse.Namespace:
    parser = argparse.ArgumentParser(description="YOLOv8 live")
    parser.add_argument(
        "--webcam-resolution", 
        default=[1280, 720], 
        nargs=2, 
        type=int
    )
    args = parser.parse_args()
    return args


def main():
    args = parse_arguments()
    frame_width, frame_height = args.webcam_resolution

    cap = cv2.VideoCapture(0)
    cap.set(cv2.CAP_PROP_FRAME_WIDTH, frame_width)
    cap.set(cv2.CAP_PROP_FRAME_HEIGHT, frame_height)

    model = YOLO("yolov8l.pt")

    objects_detected = False  

    while not objects_detected:  
        ret, frame = cap.read()

        result = model(frame, agnostic_nms=True)[0]
        detections = sv.Detections.from_yolov8(result)
        
        
        labels = [
            model.model.names[class_id].split()[0]  
            for _, _, class_id, _
            in detections
        ]
        
        detected_objects = ", ".join(set(labels))
        print("Detected objects:", detected_objects)
        speak("Detected objects are "+ detected_objects)
        
        # Displaying the frame with detections
        cv2.imshow('Object Detection', frame)
        cv2.waitKey(1000)
        
        if detections:  
            objects_detected = True
    


    cap.release()
    cv2.destroyAllWindows()


